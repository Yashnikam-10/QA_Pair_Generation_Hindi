{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"source":"<a href=\"https://www.kaggle.com/code/yashnikam10/finetunebloomz-mt-0-model?scriptVersionId=153969106\" target=\"_blank\"><img align=\"left\" alt=\"Kaggle\" title=\"Open in Kaggle\" src=\"https://kaggle.com/static/images/open-in-kaggle.svg\"></a>","metadata":{},"cell_type":"markdown"},{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2023-11-03T05:04:13.300584Z","iopub.execute_input":"2023-11-03T05:04:13.302074Z","iopub.status.idle":"2023-11-03T05:04:13.684207Z","shell.execute_reply.started":"2023-11-03T05:04:13.302031Z","shell.execute_reply":"2023-11-03T05:04:13.683255Z"},"trusted":true},"execution_count":1,"outputs":[{"name":"stdout","text":"/kaggle/input/anlp-project-dataset/prompts.json\n/kaggle/input/pls-work-15/prompts15.json\n/kaggle/input/anlp-project-prompt-5/prompts1.json\n/kaggle/input/hey-maybe-this-will-work/prompts3.json\n","output_type":"stream"}]},{"cell_type":"code","source":"!pip install datasets==2.13.1\n!pip install transformers==4.34.1\n!pip install accelerate\n!pip install peft==0.5.0","metadata":{"scrolled":true,"execution":{"iopub.status.busy":"2023-11-03T05:04:13.685738Z","iopub.execute_input":"2023-11-03T05:04:13.686124Z","iopub.status.idle":"2023-11-03T05:05:12.508995Z","shell.execute_reply.started":"2023-11-03T05:04:13.686097Z","shell.execute_reply":"2023-11-03T05:05:12.508012Z"},"trusted":true},"execution_count":2,"outputs":[{"name":"stdout","text":"Collecting datasets==2.13.1\n  Downloading datasets-2.13.1-py3-none-any.whl (486 kB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m486.2/486.2 kB\u001b[0m \u001b[31m11.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m\n\u001b[?25hRequirement already satisfied: numpy>=1.17 in /opt/conda/lib/python3.10/site-packages (from datasets==2.13.1) (1.23.5)\nRequirement already satisfied: pyarrow>=8.0.0 in /opt/conda/lib/python3.10/site-packages (from datasets==2.13.1) (11.0.0)\nCollecting dill<0.3.7,>=0.3.0 (from datasets==2.13.1)\n  Downloading dill-0.3.6-py3-none-any.whl (110 kB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m110.5/110.5 kB\u001b[0m \u001b[31m11.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hRequirement already satisfied: pandas in /opt/conda/lib/python3.10/site-packages (from datasets==2.13.1) (2.0.2)\nRequirement already satisfied: requests>=2.19.0 in /opt/conda/lib/python3.10/site-packages (from datasets==2.13.1) (2.31.0)\nRequirement already satisfied: tqdm>=4.62.1 in /opt/conda/lib/python3.10/site-packages (from datasets==2.13.1) (4.66.1)\nRequirement already satisfied: xxhash in /opt/conda/lib/python3.10/site-packages (from datasets==2.13.1) (3.3.0)\nRequirement already satisfied: multiprocess in /opt/conda/lib/python3.10/site-packages (from datasets==2.13.1) (0.70.15)\nRequirement already satisfied: fsspec[http]>=2021.11.1 in /opt/conda/lib/python3.10/site-packages (from datasets==2.13.1) (2023.9.0)\nRequirement already satisfied: aiohttp in /opt/conda/lib/python3.10/site-packages (from datasets==2.13.1) (3.8.4)\nRequirement already satisfied: huggingface-hub<1.0.0,>=0.11.0 in /opt/conda/lib/python3.10/site-packages (from datasets==2.13.1) (0.16.4)\nRequirement already satisfied: packaging in /opt/conda/lib/python3.10/site-packages (from datasets==2.13.1) (21.3)\nRequirement already satisfied: pyyaml>=5.1 in /opt/conda/lib/python3.10/site-packages (from datasets==2.13.1) (6.0)\nRequirement already satisfied: attrs>=17.3.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets==2.13.1) (23.1.0)\nRequirement already satisfied: charset-normalizer<4.0,>=2.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets==2.13.1) (3.1.0)\nRequirement already satisfied: multidict<7.0,>=4.5 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets==2.13.1) (6.0.4)\nRequirement already satisfied: async-timeout<5.0,>=4.0.0a3 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets==2.13.1) (4.0.2)\nRequirement already satisfied: yarl<2.0,>=1.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets==2.13.1) (1.9.2)\nRequirement already satisfied: frozenlist>=1.1.1 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets==2.13.1) (1.3.3)\nRequirement already satisfied: aiosignal>=1.1.2 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets==2.13.1) (1.3.1)\nRequirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from huggingface-hub<1.0.0,>=0.11.0->datasets==2.13.1) (3.12.2)\nRequirement already satisfied: typing-extensions>=3.7.4.3 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub<1.0.0,>=0.11.0->datasets==2.13.1) (4.6.3)\nRequirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /opt/conda/lib/python3.10/site-packages (from packaging->datasets==2.13.1) (3.0.9)\nRequirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests>=2.19.0->datasets==2.13.1) (3.4)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests>=2.19.0->datasets==2.13.1) (1.26.15)\nRequirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests>=2.19.0->datasets==2.13.1) (2023.7.22)\nINFO: pip is looking at multiple versions of multiprocess to determine which version is compatible with other requirements. This could take a while.\nCollecting multiprocess (from datasets==2.13.1)\n  Downloading multiprocess-0.70.14-py310-none-any.whl (134 kB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m134.3/134.3 kB\u001b[0m \u001b[31m13.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hRequirement already satisfied: python-dateutil>=2.8.2 in /opt/conda/lib/python3.10/site-packages (from pandas->datasets==2.13.1) (2.8.2)\nRequirement already satisfied: pytz>=2020.1 in /opt/conda/lib/python3.10/site-packages (from pandas->datasets==2.13.1) (2023.3)\nRequirement already satisfied: tzdata>=2022.1 in /opt/conda/lib/python3.10/site-packages (from pandas->datasets==2.13.1) (2023.3)\nRequirement already satisfied: six>=1.5 in /opt/conda/lib/python3.10/site-packages (from python-dateutil>=2.8.2->pandas->datasets==2.13.1) (1.16.0)\nInstalling collected packages: dill, multiprocess, datasets\n  Attempting uninstall: dill\n    Found existing installation: dill 0.3.7\n    Uninstalling dill-0.3.7:\n      Successfully uninstalled dill-0.3.7\n  Attempting uninstall: multiprocess\n    Found existing installation: multiprocess 0.70.15\n    Uninstalling multiprocess-0.70.15:\n      Successfully uninstalled multiprocess-0.70.15\n  Attempting uninstall: datasets\n    Found existing installation: datasets 2.1.0\n    Uninstalling datasets-2.1.0:\n      Successfully uninstalled datasets-2.1.0\n\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\napache-beam 2.46.0 requires dill<0.3.2,>=0.3.1.1, but you have dill 0.3.6 which is incompatible.\napache-beam 2.46.0 requires pyarrow<10.0.0,>=3.0.0, but you have pyarrow 11.0.0 which is incompatible.\npathos 0.3.1 requires dill>=0.3.7, but you have dill 0.3.6 which is incompatible.\npathos 0.3.1 requires multiprocess>=0.70.15, but you have multiprocess 0.70.14 which is incompatible.\npymc3 3.11.5 requires numpy<1.22.2,>=1.15.0, but you have numpy 1.23.5 which is incompatible.\npymc3 3.11.5 requires scipy<1.8.0,>=1.7.3, but you have scipy 1.11.2 which is incompatible.\u001b[0m\u001b[31m\n\u001b[0mSuccessfully installed datasets-2.13.1 dill-0.3.6 multiprocess-0.70.14\nCollecting transformers==4.34.1\n  Downloading transformers-4.34.1-py3-none-any.whl (7.7 MB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.7/7.7 MB\u001b[0m \u001b[31m63.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m0:01\u001b[0m\n\u001b[?25hRequirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from transformers==4.34.1) (3.12.2)\nRequirement already satisfied: huggingface-hub<1.0,>=0.16.4 in /opt/conda/lib/python3.10/site-packages (from transformers==4.34.1) (0.16.4)\nRequirement already satisfied: numpy>=1.17 in /opt/conda/lib/python3.10/site-packages (from transformers==4.34.1) (1.23.5)\nRequirement already satisfied: packaging>=20.0 in /opt/conda/lib/python3.10/site-packages (from transformers==4.34.1) (21.3)\nRequirement already satisfied: pyyaml>=5.1 in /opt/conda/lib/python3.10/site-packages (from transformers==4.34.1) (6.0)\nRequirement already satisfied: regex!=2019.12.17 in /opt/conda/lib/python3.10/site-packages (from transformers==4.34.1) (2023.6.3)\nRequirement already satisfied: requests in /opt/conda/lib/python3.10/site-packages (from transformers==4.34.1) (2.31.0)\nCollecting tokenizers<0.15,>=0.14 (from transformers==4.34.1)\n  Downloading tokenizers-0.14.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.8 MB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.8/3.8 MB\u001b[0m \u001b[31m84.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m\n\u001b[?25hRequirement already satisfied: safetensors>=0.3.1 in /opt/conda/lib/python3.10/site-packages (from transformers==4.34.1) (0.3.3)\nRequirement already satisfied: tqdm>=4.27 in /opt/conda/lib/python3.10/site-packages (from transformers==4.34.1) (4.66.1)\nRequirement already satisfied: fsspec in /opt/conda/lib/python3.10/site-packages (from huggingface-hub<1.0,>=0.16.4->transformers==4.34.1) (2023.9.0)\nRequirement already satisfied: typing-extensions>=3.7.4.3 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub<1.0,>=0.16.4->transformers==4.34.1) (4.6.3)\nRequirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /opt/conda/lib/python3.10/site-packages (from packaging>=20.0->transformers==4.34.1) (3.0.9)\nRequirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests->transformers==4.34.1) (3.1.0)\nRequirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests->transformers==4.34.1) (3.4)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests->transformers==4.34.1) (1.26.15)\nRequirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests->transformers==4.34.1) (2023.7.22)\nInstalling collected packages: tokenizers, transformers\n  Attempting uninstall: tokenizers\n    Found existing installation: tokenizers 0.13.3\n    Uninstalling tokenizers-0.13.3:\n      Successfully uninstalled tokenizers-0.13.3\n  Attempting uninstall: transformers\n    Found existing installation: transformers 4.33.0\n    Uninstalling transformers-4.33.0:\n      Successfully uninstalled transformers-4.33.0\nSuccessfully installed tokenizers-0.14.1 transformers-4.34.1\nRequirement already satisfied: accelerate in /opt/conda/lib/python3.10/site-packages (0.22.0)\nRequirement already satisfied: numpy>=1.17 in /opt/conda/lib/python3.10/site-packages (from accelerate) (1.23.5)\nRequirement already satisfied: packaging>=20.0 in /opt/conda/lib/python3.10/site-packages (from accelerate) (21.3)\nRequirement already satisfied: psutil in /opt/conda/lib/python3.10/site-packages (from accelerate) (5.9.3)\nRequirement already satisfied: pyyaml in /opt/conda/lib/python3.10/site-packages (from accelerate) (6.0)\nRequirement already satisfied: torch>=1.10.0 in /opt/conda/lib/python3.10/site-packages (from accelerate) (2.0.0)\nRequirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /opt/conda/lib/python3.10/site-packages (from packaging>=20.0->accelerate) (3.0.9)\nRequirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from torch>=1.10.0->accelerate) (3.12.2)\nRequirement already satisfied: typing-extensions in /opt/conda/lib/python3.10/site-packages (from torch>=1.10.0->accelerate) (4.6.3)\nRequirement already satisfied: sympy in /opt/conda/lib/python3.10/site-packages (from torch>=1.10.0->accelerate) (1.12)\nRequirement already satisfied: networkx in /opt/conda/lib/python3.10/site-packages (from torch>=1.10.0->accelerate) (3.1)\nRequirement already satisfied: jinja2 in /opt/conda/lib/python3.10/site-packages (from torch>=1.10.0->accelerate) (3.1.2)\nRequirement already satisfied: MarkupSafe>=2.0 in /opt/conda/lib/python3.10/site-packages (from jinja2->torch>=1.10.0->accelerate) (2.1.3)\nRequirement already satisfied: mpmath>=0.19 in /opt/conda/lib/python3.10/site-packages (from sympy->torch>=1.10.0->accelerate) (1.3.0)\nCollecting peft==0.5.0\n  Downloading peft-0.5.0-py3-none-any.whl (85 kB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m85.6/85.6 kB\u001b[0m \u001b[31m4.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hRequirement already satisfied: numpy>=1.17 in /opt/conda/lib/python3.10/site-packages (from peft==0.5.0) (1.23.5)\nRequirement already satisfied: packaging>=20.0 in /opt/conda/lib/python3.10/site-packages (from peft==0.5.0) (21.3)\nRequirement already satisfied: psutil in /opt/conda/lib/python3.10/site-packages (from peft==0.5.0) (5.9.3)\nRequirement already satisfied: pyyaml in /opt/conda/lib/python3.10/site-packages (from peft==0.5.0) (6.0)\nRequirement already satisfied: torch>=1.13.0 in /opt/conda/lib/python3.10/site-packages (from peft==0.5.0) (2.0.0)\nRequirement already satisfied: transformers in /opt/conda/lib/python3.10/site-packages (from peft==0.5.0) (4.34.1)\nRequirement already satisfied: tqdm in /opt/conda/lib/python3.10/site-packages (from peft==0.5.0) (4.66.1)\nRequirement already satisfied: accelerate in /opt/conda/lib/python3.10/site-packages (from peft==0.5.0) (0.22.0)\nRequirement already satisfied: safetensors in /opt/conda/lib/python3.10/site-packages (from peft==0.5.0) (0.3.3)\nRequirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /opt/conda/lib/python3.10/site-packages (from packaging>=20.0->peft==0.5.0) (3.0.9)\nRequirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from torch>=1.13.0->peft==0.5.0) (3.12.2)\nRequirement already satisfied: typing-extensions in /opt/conda/lib/python3.10/site-packages (from torch>=1.13.0->peft==0.5.0) (4.6.3)\nRequirement already satisfied: sympy in /opt/conda/lib/python3.10/site-packages (from torch>=1.13.0->peft==0.5.0) (1.12)\nRequirement already satisfied: networkx in /opt/conda/lib/python3.10/site-packages (from torch>=1.13.0->peft==0.5.0) (3.1)\nRequirement already satisfied: jinja2 in /opt/conda/lib/python3.10/site-packages (from torch>=1.13.0->peft==0.5.0) (3.1.2)\nRequirement already satisfied: huggingface-hub<1.0,>=0.16.4 in /opt/conda/lib/python3.10/site-packages (from transformers->peft==0.5.0) (0.16.4)\nRequirement already satisfied: regex!=2019.12.17 in /opt/conda/lib/python3.10/site-packages (from transformers->peft==0.5.0) (2023.6.3)\nRequirement already satisfied: requests in /opt/conda/lib/python3.10/site-packages (from transformers->peft==0.5.0) (2.31.0)\nRequirement already satisfied: tokenizers<0.15,>=0.14 in /opt/conda/lib/python3.10/site-packages (from transformers->peft==0.5.0) (0.14.1)\nRequirement already satisfied: fsspec in /opt/conda/lib/python3.10/site-packages (from huggingface-hub<1.0,>=0.16.4->transformers->peft==0.5.0) (2023.9.0)\nRequirement already satisfied: MarkupSafe>=2.0 in /opt/conda/lib/python3.10/site-packages (from jinja2->torch>=1.13.0->peft==0.5.0) (2.1.3)\nRequirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests->transformers->peft==0.5.0) (3.1.0)\nRequirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests->transformers->peft==0.5.0) (3.4)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests->transformers->peft==0.5.0) (1.26.15)\nRequirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests->transformers->peft==0.5.0) (2023.7.22)\nRequirement already satisfied: mpmath>=0.19 in /opt/conda/lib/python3.10/site-packages (from sympy->torch>=1.13.0->peft==0.5.0) (1.3.0)\nInstalling collected packages: peft\nSuccessfully installed peft-0.5.0\n","output_type":"stream"}]},{"cell_type":"code","source":"import datasets\nimport json\nimport torch\nimport pandas as pd\nimport transformers\nfrom transformers import BloomTokenizerFast, BloomForCausalLM, TrainingArguments, Trainer\nfrom transformers import AutoModelForSeq2SeqLM, AutoTokenizer\nfrom datasets import load_dataset, Dataset\nfrom accelerate import Accelerator","metadata":{"execution":{"iopub.status.busy":"2023-11-03T05:05:12.510395Z","iopub.execute_input":"2023-11-03T05:05:12.510694Z","iopub.status.idle":"2023-11-03T05:05:25.312369Z","shell.execute_reply.started":"2023-11-03T05:05:12.510668Z","shell.execute_reply":"2023-11-03T05:05:25.311373Z"},"trusted":true},"execution_count":3,"outputs":[{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/scipy/__init__.py:146: UserWarning: A NumPy version >=1.16.5 and <1.23.0 is required for this version of SciPy (detected version 1.23.5\n  warnings.warn(f\"A NumPy version >={np_minversion} and <{np_maxversion}\"\n","output_type":"stream"}]},{"cell_type":"code","source":"device = torch.device(\"cuda\") if torch.cuda.is_available() else torch.device(\"cpu\")","metadata":{"execution":{"iopub.status.busy":"2023-11-03T05:05:25.315882Z","iopub.execute_input":"2023-11-03T05:05:25.316196Z","iopub.status.idle":"2023-11-03T05:05:25.345527Z","shell.execute_reply.started":"2023-11-03T05:05:25.316169Z","shell.execute_reply":"2023-11-03T05:05:25.3443Z"},"trusted":true},"execution_count":4,"outputs":[]},{"cell_type":"code","source":"from transformers import AutoModelForCausalLM, AutoTokenizer","metadata":{"execution":{"iopub.status.busy":"2023-11-03T05:05:25.346646Z","iopub.execute_input":"2023-11-03T05:05:25.347143Z","iopub.status.idle":"2023-11-03T05:05:25.364425Z","shell.execute_reply.started":"2023-11-03T05:05:25.3471Z","shell.execute_reply":"2023-11-03T05:05:25.363673Z"},"trusted":true},"execution_count":5,"outputs":[]},{"cell_type":"code","source":"checkpoint = \"bigscience/mt0-base\"\n\ntokenizer = AutoTokenizer.from_pretrained(checkpoint)\nmodel = AutoModelForSeq2SeqLM.from_pretrained(checkpoint, torch_dtype=\"auto\", device_map=\"auto\")","metadata":{"execution":{"iopub.status.busy":"2023-11-03T05:05:25.365437Z","iopub.execute_input":"2023-11-03T05:05:25.365719Z","iopub.status.idle":"2023-11-03T05:06:53.89857Z","shell.execute_reply.started":"2023-11-03T05:05:25.365697Z","shell.execute_reply":"2023-11-03T05:06:53.897735Z"},"trusted":true},"execution_count":6,"outputs":[{"output_type":"display_data","data":{"text/plain":"Downloading (…)okenizer_config.json:   0%|          | 0.00/430 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"25356d0316e5430ea1c2c910e7d253f7"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading spiece.model:   0%|          | 0.00/4.31M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"1cf0986ae0cb406fb808fabdd80047b6"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading tokenizer.json:   0%|          | 0.00/16.3M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"b8ba15087ed444529a7b149f74389af0"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading (…)cial_tokens_map.json:   0%|          | 0.00/74.0 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"495afd8681c8420ca0675ea8b22e25c7"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading (…)lve/main/config.json:   0%|          | 0.00/798 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"a49d122a951047d0a3736aea27a253c5"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading model.safetensors:   0%|          | 0.00/2.33G [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"8046033087c741978e9c67f5a8d0dbab"}},"metadata":{}}]},{"cell_type":"code","source":"# import os \n# os.environ[\"PYTORCH_CUDA_ALLOC_CONF\"] = \"caching-allocator\"","metadata":{"execution":{"iopub.status.busy":"2023-11-03T05:06:53.899635Z","iopub.execute_input":"2023-11-03T05:06:53.899915Z","iopub.status.idle":"2023-11-03T05:06:53.904077Z","shell.execute_reply.started":"2023-11-03T05:06:53.89989Z","shell.execute_reply":"2023-11-03T05:06:53.903072Z"},"trusted":true},"execution_count":7,"outputs":[]},{"cell_type":"code","source":"import transformers\ndata_collator = transformers.DataCollatorForTokenClassification(tokenizer=tokenizer)","metadata":{"execution":{"iopub.status.busy":"2023-11-03T05:06:53.905273Z","iopub.execute_input":"2023-11-03T05:06:53.905986Z","iopub.status.idle":"2023-11-03T05:06:53.916743Z","shell.execute_reply.started":"2023-11-03T05:06:53.905961Z","shell.execute_reply":"2023-11-03T05:06:53.915955Z"},"trusted":true},"execution_count":8,"outputs":[]},{"cell_type":"code","source":"dataset = load_dataset(\"json\", data_files=\"/kaggle/input/pls-work-15/prompts15.json\")","metadata":{"execution":{"iopub.status.busy":"2023-11-03T05:06:53.917841Z","iopub.execute_input":"2023-11-03T05:06:53.918112Z","iopub.status.idle":"2023-11-03T05:06:54.37026Z","shell.execute_reply.started":"2023-11-03T05:06:53.91809Z","shell.execute_reply":"2023-11-03T05:06:54.369362Z"},"trusted":true},"execution_count":9,"outputs":[{"name":"stdout","text":"Downloading and preparing dataset json/default to /root/.cache/huggingface/datasets/json/default-1cb6d37db145a303/0.0.0/8bb11242116d547c741b2e8a1f18598ffdd40a1d4f2a2872c7a28b697434bc96...\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Downloading data files:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"104c9cc973e246b6ab2f2747589e8687"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Extracting data files:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"684392e74565484eaf70480054b737c5"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Generating train split: 0 examples [00:00, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"name":"stdout","text":"Dataset json downloaded and prepared to /root/.cache/huggingface/datasets/json/default-1cb6d37db145a303/0.0.0/8bb11242116d547c741b2e8a1f18598ffdd40a1d4f2a2872c7a28b697434bc96. Subsequent calls will reuse this data.\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"8d44abf937ec422eaabe721fae2971e1"}},"metadata":{}}]},{"cell_type":"code","source":"# !pip install -U datasets","metadata":{"scrolled":true,"execution":{"iopub.status.busy":"2023-11-03T05:06:54.373649Z","iopub.execute_input":"2023-11-03T05:06:54.373942Z","iopub.status.idle":"2023-11-03T05:06:54.377751Z","shell.execute_reply.started":"2023-11-03T05:06:54.373917Z","shell.execute_reply":"2023-11-03T05:06:54.376846Z"},"trusted":true},"execution_count":10,"outputs":[]},{"cell_type":"code","source":"dataset","metadata":{"execution":{"iopub.status.busy":"2023-11-03T05:06:54.37907Z","iopub.execute_input":"2023-11-03T05:06:54.379398Z","iopub.status.idle":"2023-11-03T05:06:54.392222Z","shell.execute_reply.started":"2023-11-03T05:06:54.379368Z","shell.execute_reply":"2023-11-03T05:06:54.391377Z"},"trusted":true},"execution_count":11,"outputs":[{"execution_count":11,"output_type":"execute_result","data":{"text/plain":"DatasetDict({\n    train: Dataset({\n        features: ['text'],\n        num_rows: 15\n    })\n})"},"metadata":{}}]},{"cell_type":"code","source":"# tokenizer.max_length()","metadata":{"execution":{"iopub.status.busy":"2023-11-03T05:06:54.393293Z","iopub.execute_input":"2023-11-03T05:06:54.393558Z","iopub.status.idle":"2023-11-03T05:06:54.401763Z","shell.execute_reply.started":"2023-11-03T05:06:54.393529Z","shell.execute_reply":"2023-11-03T05:06:54.400779Z"},"trusted":true},"execution_count":12,"outputs":[]},{"cell_type":"code","source":"def prepare_train_data(data):\n    # prompt + completion\n    #text_input = data['prompt'] + ' ' + data['completion']\n    text_input = data['text']\n    # tokenize the input (prompt + completion) text\n    tokenized_input = tokenizer(text_input, return_tensors='pt', padding='max_length', truncation=True, max_length=2500)\n    # generative models: labels are the same as the input\n    tokenized_input['labels'] = tokenized_input['input_ids']\n    return tokenized_input","metadata":{"execution":{"iopub.status.busy":"2023-11-03T05:06:54.402922Z","iopub.execute_input":"2023-11-03T05:06:54.403178Z","iopub.status.idle":"2023-11-03T05:06:54.41267Z","shell.execute_reply.started":"2023-11-03T05:06:54.403156Z","shell.execute_reply":"2023-11-03T05:06:54.411853Z"},"trusted":true},"execution_count":13,"outputs":[]},{"cell_type":"code","source":"train_dataset = dataset.map(prepare_train_data,batched=True, remove_columns=[\"text\"])","metadata":{"execution":{"iopub.status.busy":"2023-11-03T05:06:54.413766Z","iopub.execute_input":"2023-11-03T05:06:54.414058Z","iopub.status.idle":"2023-11-03T05:06:54.587048Z","shell.execute_reply.started":"2023-11-03T05:06:54.414036Z","shell.execute_reply":"2023-11-03T05:06:54.586125Z"},"trusted":true},"execution_count":14,"outputs":[{"output_type":"display_data","data":{"text/plain":"Map:   0%|          | 0/15 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}}]},{"cell_type":"code","source":"training_arguments = TrainingArguments(\n    '/kaggle/working/HindiQA-bloomz-560m',\n    learning_rate=1e-4,\n    per_device_train_batch_size=1,\n    num_train_epochs=8,\n    weight_decay=0.01,\n    optim=\"adafactor\",\n    gradient_accumulation_steps=4,\n    gradient_checkpointing=True,\n)","metadata":{"execution":{"iopub.status.busy":"2023-11-03T05:06:54.588215Z","iopub.execute_input":"2023-11-03T05:06:54.588487Z","iopub.status.idle":"2023-11-03T05:06:54.596055Z","shell.execute_reply.started":"2023-11-03T05:06:54.588463Z","shell.execute_reply":"2023-11-03T05:06:54.595251Z"},"trusted":true},"execution_count":15,"outputs":[]},{"cell_type":"code","source":"trainer = Trainer(\n    model = model,\n    args = training_arguments,\n    train_dataset = train_dataset[\"train\"],\n    tokenizer=tokenizer,\n    data_collator=data_collator\n)","metadata":{"execution":{"iopub.status.busy":"2023-11-03T05:06:54.597088Z","iopub.execute_input":"2023-11-03T05:06:54.597411Z","iopub.status.idle":"2023-11-03T05:06:54.61617Z","shell.execute_reply.started":"2023-11-03T05:06:54.597378Z","shell.execute_reply":"2023-11-03T05:06:54.615349Z"},"trusted":true},"execution_count":16,"outputs":[]},{"cell_type":"code","source":"trainer.train()","metadata":{"execution":{"iopub.status.busy":"2023-11-03T05:06:54.617329Z","iopub.execute_input":"2023-11-03T05:06:54.617972Z","iopub.status.idle":"2023-11-03T05:12:21.88618Z","shell.execute_reply.started":"2023-11-03T05:06:54.617939Z","shell.execute_reply":"2023-11-03T05:12:21.885275Z"},"trusted":true},"execution_count":17,"outputs":[{"name":"stderr","text":"\u001b[34m\u001b[1mwandb\u001b[0m: Logging into wandb.ai. (Learn how to deploy a W&B server locally: https://wandb.me/wandb-server)\n\u001b[34m\u001b[1mwandb\u001b[0m: You can find your API key in your browser here: https://wandb.ai/authorize\n\u001b[34m\u001b[1mwandb\u001b[0m: Paste an API key from your profile and hit enter, or press ctrl+c to quit:","output_type":"stream"},{"output_type":"stream","name":"stdin","text":"  ········································\n"},{"name":"stderr","text":"\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /root/.netrc\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"wandb version 0.15.12 is available!  To upgrade, please run:\n $ pip install wandb --upgrade"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Tracking run with wandb version 0.15.9"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Run data is saved locally in <code>/kaggle/working/wandb/run-20231103_050720-xaj0j7z6</code>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Syncing run <strong><a href='https://wandb.ai/anlpgroup/huggingface/runs/xaj0j7z6' target=\"_blank\">youthful-salad-44</a></strong> to <a href='https://wandb.ai/anlpgroup/huggingface' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View project at <a href='https://wandb.ai/anlpgroup/huggingface' target=\"_blank\">https://wandb.ai/anlpgroup/huggingface</a>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View run at <a href='https://wandb.ai/anlpgroup/huggingface/runs/xaj0j7z6' target=\"_blank\">https://wandb.ai/anlpgroup/huggingface/runs/xaj0j7z6</a>"},"metadata":{}},{"name":"stderr","text":"You're using a T5TokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n    <div>\n      \n      <progress value='24' max='24' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [24/24 04:17, Epoch 6/8]\n    </div>\n    <table border=\"1\" class=\"dataframe\">\n  <thead>\n <tr style=\"text-align: left;\">\n      <th>Step</th>\n      <th>Training Loss</th>\n    </tr>\n  </thead>\n  <tbody>\n  </tbody>\n</table><p>"},"metadata":{}},{"execution_count":17,"output_type":"execute_result","data":{"text/plain":"TrainOutput(global_step=24, training_loss=10.981741587320963, metrics={'train_runtime': 326.9812, 'train_samples_per_second': 0.367, 'train_steps_per_second': 0.073, 'total_flos': 562052874240000.0, 'train_loss': 10.981741587320963, 'epoch': 6.4})"},"metadata":{}}]},{"cell_type":"code","source":"trainer.save_model()","metadata":{"execution":{"iopub.status.busy":"2023-11-03T05:12:21.887381Z","iopub.execute_input":"2023-11-03T05:12:21.887642Z","iopub.status.idle":"2023-11-03T05:12:25.919858Z","shell.execute_reply.started":"2023-11-03T05:12:21.887618Z","shell.execute_reply":"2023-11-03T05:12:25.91883Z"},"trusted":true},"execution_count":18,"outputs":[]},{"cell_type":"code","source":"tokenizer = AutoTokenizer.from_pretrained(\"/kaggle/working/HindiQA-bloomz-560m\")","metadata":{"execution":{"iopub.status.busy":"2023-11-03T05:12:25.921168Z","iopub.execute_input":"2023-11-03T05:12:25.921514Z","iopub.status.idle":"2023-11-03T05:12:26.475186Z","shell.execute_reply.started":"2023-11-03T05:12:25.921482Z","shell.execute_reply":"2023-11-03T05:12:26.474041Z"},"trusted":true},"execution_count":19,"outputs":[]},{"cell_type":"code","source":"model = AutoModelForSeq2SeqLM.from_pretrained(\"./HindiQA-bloomz-560m\")","metadata":{"execution":{"iopub.status.busy":"2023-11-03T05:12:26.476583Z","iopub.execute_input":"2023-11-03T05:12:26.476907Z","iopub.status.idle":"2023-11-03T05:12:36.111743Z","shell.execute_reply.started":"2023-11-03T05:12:26.47688Z","shell.execute_reply":"2023-11-03T05:12:36.110648Z"},"trusted":true},"execution_count":20,"outputs":[]},{"cell_type":"code","source":"essay = '\"दलाई लामा ने अपनी संवेदना और प्रार्थना व्यक्त की और कलाम की मौत को \"एक अपूरणीय क्षति\" बुला, अपना दुख व्यक्त किया। उन्होंने यह भी कहा, \"अनेक वर्षों में, मुझे कई अवसरों पर कलाम के साथ बातचीत करने का मौका मिला। वह एक महान वैज्ञानिक, शिक्षाविद और राजनेता ही नहीं, बल्कि वे एक वास्तविक सज्जन थे, और हमेशा मैंने उनकी सादगी और विनम्रता की प्रशंसा की है। मैंने सामान्य हितों के विषयों की एक विस्तृत श्रृंखला पर हमारी चर्चाओं का आनंद लिया, लेकिन विज्ञान, अध्यात्म और शिक्षा के साथ मुख्य रूप से हमारे बीच चिंतन किया जाता था। \" दक्षिण एशियाई नेताओं ने अपनी संवेदना व्यक्त की और दिवंगत राजनेता की सराहना की। भूटान सरकार ने कलाम की मौत के शोक के लिए देश के झंडे को आधी ऊंचाई पर फहराने के लिए आदेश दिया, और श्रद्धांजलि में 1000 मक्खन के दीपक की भेंट किए। भूटान के प्रधानमंत्री शेरिंग तोबगे ने कलाम के प्रति अपना गहरा दुख व्यक्त करते हुए कहा, \"वे एक महान नेता थे जिनकी सभी ने प्रशंसा की विशेषकर भारत के युवाओं के वे प्रशंसनीय नेता थे जिन्हें वे जनता का राष्ट्रपति बुलाते थे। \"बांग्लादेश की प्रधानमंत्री शेख हसीना ने उनकी व्याख्या करते हुए कहा, \"एक महान राजनेता प्रशंसित वैज्ञानिक और दक्षिण एशिया के युवा पीढ़ी के लिए प्रेरणा स्रोत के संयोग\" उन्होंने कलाम की मृत्यु को \"भारत के लिए अपूरणीय क्षति से भी परे बताया। \" उन्होंने यह भी कहा कि भारत के सबसे प्रसिद्ध बेटे, पूर्व राष्ट्रपति के निधन पर हमें गहरा झटका लगा है। ए॰पी॰जे॰ अब्दुल कलाम अपने समय के सबसे महान ज्ञानियों में से एक थे। वह बांग्लादेश में भी बहुत सम्मानित थे। उनकी विज्ञान और प्रौद्योगिकी के क्षेत्र में भारत की वृद्धि करने के लिए अमूल्य योगदान के लिए वे सभी के द्वारा हमेशा याद किये जायेंगे। वे दक्षिण एशिया की युवा पीढ़ी के लिए प्रेरणा का स्रोत थे जो उनके सपनों को पंख देते थे। \" बांग्लादेश नेशनलिस्ट पार्टी की प्रमुख खालिदा जिया ने कहा, \"एक परमाणु वैज्ञानिक के रूप में, उन्होंने लोगों के कल्याण में स्वयं को समर्पित किया। \"अफगानिस्तान के राष्ट्रपति अशरफ गनी, ने कलाम को, \"लाखों लोगों के लिए एक प्रेरणादायक शख्सियत बताया\" ये नोट करते हुए \"हमे अपने जीवन से बहुत कुछ सीखना है। \" नेपाली प्रधानमंत्री सुशील कोइराला ने भारत के लिए कलाम के वैज्ञानिक योगदानों को याद किया। \"नेपाल ने एक अच्छा दोस्त खो दिया है और मैंने एक सम्मानित और आदर्श व्यक्तित्व को खो दिया है। \"पाकिस्तान के राष्ट्रपति, ममनून हुसैन और पाकिस्तान के प्रधानमंत्री नवाज शरीफ ने पूर्व राष्ट्रपति के निधन पर उनके प्रति दु: ख, शोक व संवेदना व्यक्त की। श्रीलंका के राष्ट्रपति मैत्रिपाला सिरिसेना ने कहा, \"कलाम दृढ़ विश्वास और अदम्य भावना के आदमी थे। मैंने उन्हें दुनिया के एक उत्कृष्ट राजनेता के रूप में देखा था। उनकी मौत भारत के लिए, बल्कि पूरी दुनिया के लिए अपूरणीय क्षति है। \"इंडोनेशियाई राष्ट्रपति सुसीलो बम्बनग युधोयोनो, मलेशिया के प्रधानमंत्री नजीब रजाक, सिंगापुर के प्रधानमंत्री ली सियन लूंग , संयुक्त अरब अमीरात के राष्ट्रपति शेख खलीफा बिन जायद अल नहयान सहित अन्य अंतरराष्ट्रीय नेताओं,, और संयुक्त अरब अमीरात के प्रधानमंत्री और दुबई के शासक ने भी कलाम को श्रद्धांजलि अर्पित की। रूसी राष्ट्रपति व्लादिमीर पुतिन ने भारत सरकार, भारत के सभी लोगों के लिए और मृतक नेता ले प्रियजनों के लिए अपनी गंभीर संवेदना व्यक्त की और अपनी सहानुभूति और समर्थन से अवगत कराते हुए कहा, \"कलाम को हमारे देशों के बीच लगातार मैत्रीपूर्ण संबंधों के एक प्रतिपादक के रूप में याद किया जाएगा, उन्होंने भारत की राष्ट्रीय सुरक्षा को सुनिश्चित करने में सामाजिक, आर्थिक, वैज्ञानिक और तकनीकी प्रगति के लिए व्यक्तिगत योगदान दिया। उन्होंने  पारस्परिक रूप से लाभप्रद रूसी-भारतीय सहयोग जोड़ने के लिए बहुत कुछ किया। \"संयुक्त राज्य अमेरिका के राष्ट्रपति बराक ओबामा ने कहा,\" अमेरिकी लोगों की ओर से, मैं पूर्व भारतीय राष्ट्रपति ए॰पी॰जे॰ अब्दुल कलाम के निधन पर भारत के लोगों के लिए अपनी गहरी संवेदना का विस्तार करना चाहता हूँ। एक वैज्ञानिक और राजनेता, कलाम ने अपनी विनम्रता से घर में और विदेशों में सम्मान कमाया और भारत के सबसे महान नेताओं में से एक बने। भारत-अमेरिका के मजबूत संबंधों के लिए, डा कलाम ने सदा वकालत की। 1962 में संयुक्त राज्य अमेरिका की यात्रा के दौरान नासा के साथ अंतरिक्ष सहयोग को गहरा करने के लिए काम किया।'","metadata":{"execution":{"iopub.status.busy":"2023-11-03T05:12:36.113331Z","iopub.execute_input":"2023-11-03T05:12:36.113638Z","iopub.status.idle":"2023-11-03T05:12:36.129113Z","shell.execute_reply.started":"2023-11-03T05:12:36.11361Z","shell.execute_reply":"2023-11-03T05:12:36.128197Z"},"trusted":true},"execution_count":21,"outputs":[]},{"cell_type":"code","source":"prompt = 'Given the context delimited by triple backticks ```'+ essay + '```, generate some questions from the given context. Questions:'\ngenerator = transformers.pipeline('text2text-generation', model=model, tokenizer=tokenizer,do_sample=False)\nresult = generator(prompt, max_new_tokens=128)\nprint(result)","metadata":{"execution":{"iopub.status.busy":"2023-11-03T05:12:36.132242Z","iopub.execute_input":"2023-11-03T05:12:36.13252Z","iopub.status.idle":"2023-11-03T05:12:50.129676Z","shell.execute_reply.started":"2023-11-03T05:12:36.132497Z","shell.execute_reply":"2023-11-03T05:12:50.128664Z"},"trusted":true},"execution_count":22,"outputs":[{"name":"stdout","text":"[{'generated_text': \"'कलाम दृढ़ विश्वास और अदम्य भावना के आदमी थे'\"}]\n","output_type":"stream"}]},{"cell_type":"code","source":"question = result[0]['generated_text']\nprompt2 = 'Given the context delimited by triple backticks ```'+ essay + '```,and the question delimited by single backticks `'+ question + '` generate an answer.Answer:'","metadata":{"execution":{"iopub.status.busy":"2023-11-03T05:12:50.131084Z","iopub.execute_input":"2023-11-03T05:12:50.131682Z","iopub.status.idle":"2023-11-03T05:12:50.13741Z","shell.execute_reply.started":"2023-11-03T05:12:50.131647Z","shell.execute_reply":"2023-11-03T05:12:50.136534Z"},"trusted":true},"execution_count":23,"outputs":[]},{"cell_type":"code","source":"generator = transformers.pipeline('text2text-generation', model=model, tokenizer=tokenizer,do_sample=False)\nresult = generator(prompt2, max_new_tokens=128)\nprint(result)","metadata":{"execution":{"iopub.status.busy":"2023-11-03T05:12:50.138851Z","iopub.execute_input":"2023-11-03T05:12:50.139407Z","iopub.status.idle":"2023-11-03T05:12:55.230356Z","shell.execute_reply.started":"2023-11-03T05:12:50.139373Z","shell.execute_reply":"2023-11-03T05:12:55.229305Z"},"trusted":true},"execution_count":24,"outputs":[{"name":"stdout","text":"[{'generated_text': \"'कलाम दृढ़ विश्वास और अदम्य भावना के आदमी थे'\"}]\n","output_type":"stream"}]},{"cell_type":"code","source":"essay = 'पेड़ों को हरा सोना भी कहा जाता है क्योंकि यह बहुत मूल्यवान सम्पदा है। धरती पर जीवन प्रदान करने वाली ऑक्सीजन और पानी प्रदान करने वाला मुख्य साधन पेड़ ही है। ऑक्सीजन प्रदान करने का कार्य और कोई नहीं कर सकता और पेड़ों के बिना पानी की कल्पना करना मुश्किल ही नहीं, नामुमकिन है।पेड़ वायु प्रदूषण कम करने में हमारी सहायता कर पर्यावरण को शुद्ध रखते हैं। मात्र वायु प्रदूषण ही नहीं ये, हानिकारक रसायनों का छानकर जल को भी साफ करते हैं। हर उद्योग में पेड़ के उत्पाद का मुख्य योगदान रहता है। हमारे दैनिक जीवन में उपयोग होने वाली वस्तुओं में पेड़ों का बहुत महत्व है।जितने अधिक पेड़ होंगे पर्यावरण भी उतना ही शुद्ध रहेगा। आजकल लोगों को वायु प्रदूषण के कारण कई प्रकार के साँस के एवं अन्य रोगों से पीड़ित होना पड़ रहा है।यदि पेड़ होंगे तो हवा में मिली हानिकारक गैसों को शोषित कर हमें स्वच्छ हवा प्रदान करेंगे और रोगों से छुटकारा भी। यदि हम पेड़ों की संख्या में वृद्धि करेंगे तो ये प्राकृतिक रुप से हवा को स्वच्छ करने के साथ हमें और भी कई फायदे पहुँचायेंगे। इनकी वृद्धि से हम एयर कंडीशनर के उपयोग से बच कर इससे निकलने वाली हानिकारक गैसों से भी निजात दिलाते हैं। पेड़ के कारण ही हमें भरपूर वर्षा प्राप्त होती है।पेड़ की जड़े मिट्टी को बांध कर रखती हैं जिनसे भूमि कटाव भी नहीं होता व भूमि जल को अच्छे से अवशोषित कर लेती है। यही जल भूमिगत जल बनकर हमें मनुष्य में पानी के अभाव से बचाता है। पेड़ हमें छाया प्रदान कर गर्मी के प्रभाव से भी धरती को बचाते हैं।इस अमूल्य सम्पदा की कमी से धरती पर ग्लोबल वार्मिंग, सूखा, भूमि कटाव जैसे समस्यायें अपना विकराल रूप लेती जा रही हैं। यदि हम इस प्राकृतिक आपदाओं से बचना चाहते हैं तो हमें पेड़ों के संरक्षण की ओर कदम उठाने ही होंगे।यदि आज हम इस दिशा में कार्य करेंगे तभी भावी पीढ़ी को भी इस ओर काम करने की प्रेरणा मिलेगी। ख़ुशी के अवसर पर हम पैसा खर्च करते हैं, दावतें करते हैं लेकिन इन सब के बजाय हम पौधारोपण और पेड़ों का संरक्षण करें तो ये सिर्फ हमारे जान-पहचान वालों के लिए ही नहीं बल्कि मनुष्य के लिए भी ख़ुशी का संकेत होगी।'","metadata":{"execution":{"iopub.status.busy":"2023-11-03T05:12:55.234296Z","iopub.execute_input":"2023-11-03T05:12:55.234569Z","iopub.status.idle":"2023-11-03T05:12:55.247943Z","shell.execute_reply.started":"2023-11-03T05:12:55.234545Z","shell.execute_reply":"2023-11-03T05:12:55.246857Z"},"trusted":true},"execution_count":25,"outputs":[]},{"cell_type":"code","source":"prompt = 'Given the context delimited by triple backticks ```'+ essay + '```, generate some questions from the given context. Questions:'\ngenerator = transformers.pipeline('text2text-generation', model=model, tokenizer=tokenizer,do_sample=False)\nresult = generator(prompt, max_new_tokens=128)\nprint(result)","metadata":{"execution":{"iopub.status.busy":"2023-11-03T05:12:55.250169Z","iopub.execute_input":"2023-11-03T05:12:55.251245Z","iopub.status.idle":"2023-11-03T05:12:58.097213Z","shell.execute_reply.started":"2023-11-03T05:12:55.25121Z","shell.execute_reply":"2023-11-03T05:12:58.096187Z"},"trusted":true},"execution_count":26,"outputs":[{"name":"stdout","text":"[{'generated_text': 'पेड़ों का संरक्षण करने के लिए हम कदम उठाने ही होंगे?'}]\n","output_type":"stream"}]},{"cell_type":"code","source":"question = result[0]['generated_text']\nprompt2 = 'Given the context delimited by triple backticks ```'+ essay + '```,and the question delimited by single backticks `'+ question + '` generate an answer.Answer:'","metadata":{"execution":{"iopub.status.busy":"2023-11-03T05:12:58.098742Z","iopub.execute_input":"2023-11-03T05:12:58.099382Z","iopub.status.idle":"2023-11-03T05:12:58.104635Z","shell.execute_reply.started":"2023-11-03T05:12:58.099349Z","shell.execute_reply":"2023-11-03T05:12:58.103721Z"},"trusted":true},"execution_count":27,"outputs":[]},{"cell_type":"code","source":"generator = transformers.pipeline('text2text-generation', model=model, tokenizer=tokenizer,do_sample=False)\nresult = generator(prompt2, max_new_tokens=128)\nprint(result)","metadata":{"execution":{"iopub.status.busy":"2023-11-03T05:12:58.110274Z","iopub.execute_input":"2023-11-03T05:12:58.110559Z","iopub.status.idle":"2023-11-03T05:13:02.272785Z","shell.execute_reply.started":"2023-11-03T05:12:58.11053Z","shell.execute_reply":"2023-11-03T05:13:02.271722Z"},"trusted":true},"execution_count":28,"outputs":[{"name":"stdout","text":"[{'generated_text': 'यदि हम इस प्राकृतिक आपदाओं से बचना चाहते हैं तो हमें पेड़ों के संरक्षण की ओर कदम उठाने ही होंगे।'}]\n","output_type":"stream"}]},{"cell_type":"code","source":"essay = 'अकबर के हिन्दू सामंत उसकी अनुमति के बगैर मंदिर निर्माण तक नहीं करा सकते थे। बंगाल में राजा मानसिंह ने एक मंदिर का निर्माण बिना अनुमति के आरंभ किया, तो अकबर ने पता चलने पर उसे रुकवा दिया और १५९५ में उसे मस्जिद में बदलने के आदेश दिए। अकबर के लिए आक्रोश की हद एक घटना से पता चलती है। हिन्दू किसानों के एक नेता राजा राम ने अकबर के मकबरे, सिकंदरा, आगरा को लूटने का प्रयास किया, जिसे स्थानीय फ़ौजदार, मीर अबुल फजल ने असफल कर दिया। इसके कुछ ही समय बाद १६८८ में राजा राम सिकंदरा में दोबारा प्रकट हुआ और शाइस्ता खां के आने में विलंब का फायदा उठाते हुए, उसने मकबरे पर दोबारा सेंध लगाई और बहुत से बहुमूल्य सामान, जैसे सोने, चाँदी, बहुमूल्य कालीन, चिराग, इत्यादि लूट लिए, तथा जो ले जा नहीं सका, उन्हें बर्बाद कर गया। राजा राम और उसके आदमियों ने अकबर की अस्थियों को खोद कर निकाल लिया एवं जला कर भस्म कर दिया, जो कि मुस्लिमों के लिए घोर अपमान का विषय था। बाद के वर्षों में अकबर को अन्य धर्मों के प्रति भी आकर्षण हुआ। अकबर का हिंदू धर्म के प्रति लगाव केवल मुग़ल साम्राज्य को ठोस बनाने के ही लिए नही था वरन उसकी हिंदू धर्म में व्यक्तिगत रुचि थी। हिंदू धर्म के अलावा अकबर को शिया इस्लाम एवं ईसाई धर्म में भी रुचि थी। ईसाई धर्म के मूलभूत सिद्धांत जानने के लिए उसने एक बार एक पुर्तगाली ईसाई धर्म प्रचारक को गोआ से बुला भेजा था। अकबर ने दरबार में एक विशेष जगह बनवाई थी जिसे इबादत-खाना (प्रार्थना-स्थल) कहा जाता था, जहाँ वह विभिन्न धर्मगुरुओं एवं प्रचारकों से धार्मिक चर्चाएं किया करता था। उसका यह दूसरे धर्मों का अन्वेषण कुछ मुस्लिम कट्टरपंथी लोगों के लिए असहनीय था। उन्हे लगने लगा था कि अकबर अपने धर्म से भटक रहा है। इन बातों में कुछ सच्चाई भी थी, अकबर ने कई बार रुढ़िवादी इस्लाम से हट कर भी कुछ फैसले लिए, यहाँ तक कि १५८२ में उसने एक नये सम्प्रदाय की ही शुरुआत कर दी जिसे दीन-ए-इलाही यानी ईश्वर का धर्म कहा गया। दीन-ए-इलाही नाम से अकबर ने १५८२ में एक नया धर्म बनाया जिसमें सभी धर्मो के मूल तत्वों को डाला, इसमे प्रमुखतः हिंदू एवं इस्लाम धर्म थे। इनके अलावा पारसी, जैन एवं ईसाई धर्म के मूल विचारों को भी सम्मिलित किया। हालांकि इस धर्म के प्रचार के लिए उसने कुछ अधिक उद्योग नहीं किये केवल अपने विश्वस्त लोगो को ही इसमे सम्मिलित किया। कहा जाता हैं कि अकबर के अलावा केवल राजा बीरबल ही मृत्यु तक इस के अनुयायी थे। दबेस्तान-ए-मजहब के अनुसार अकबर के पश्चात केवल १९ लोगो ने इस धर्म को अपनाया। कालांतर में अकबर ने एक नए पंचांग की रचना की जिसमे कि उसने एक ईश्वरीय संवत को आरम्भ किया जो उसके ही राज्याभिषेक के दिन से प्रारम्भ होता था। उसने तत्कालीन सिक्कों के पीछे ‘‘अल्लाह-ओ-अकबर’’ लिखवाया जो अनेकार्थी शब्द था। अकबर का शाब्दिक अर्थ है \"महान\" और ‘‘अल्लाह-ओ-अकबर’’ शब्द के दो अर्थ हो सकते थे \"अल्लाह महान हैं \" या \"अकबर ही अल्लाह हैं\"। दीन-ए-इलाही सही मायनो में धर्म न होकर एक आचार संहिता के समान था। इसमे भोग, घमंड, निंदा करना या दोष लगाना वर्जित थे एवं इन्हे पाप कहा गया। दया, विचारशीलता और संयम इसके आधार स्तम्भ थे। यह तर्क दिया गया है कि दीन-ए-इलैही का एक नया धर्म होने का सिद्धांत गलत धारणा है, जो कि बाद में ब्रिटिश इतिहासकारों द्वारा अबुल फजल के कार्यों के गलत अनुवाद के कारण पैदा हुआ था। हालांकि, यह भी स्वीकार किया जाता है कि सुलह-ए-कुल की नीति, जिसमें दीन-ई-इलैही का सार था, अकबर ने केवल धार्मिक उद्देश्यों के लिए नहीं बल्कि सामान्य शाही प्रशासनिक नीति का एक भाग के रूप में अपनाया था। इसने अकबर की धार्मिक सहानुभूति की नीति का आधार बनाया। 1605 में अकबर की मौत के समय उनके मुस्लिम विषयों में असंतोष का कोई संकेत नहीं था, और अब्दुल हक जैसे एक धर्मशास्त्री की धारणा थी कि निकट संबंध बने रहे। र्वधर्म मैत्री सुलह-ए-कुल सूफियों का मूल सिद्धांत रहा है। प्रसिद्ध सूफी शायर रूमी के पास एक व्यक्ति आया और कहने लगा- एक मुसलमान एक ईसाई से सहमत नहीं होता और ईसाई यहूदी से।'","metadata":{"execution":{"iopub.status.busy":"2023-11-03T05:13:02.274491Z","iopub.execute_input":"2023-11-03T05:13:02.275011Z","iopub.status.idle":"2023-11-03T05:13:02.288405Z","shell.execute_reply.started":"2023-11-03T05:13:02.27497Z","shell.execute_reply":"2023-11-03T05:13:02.287495Z"},"trusted":true},"execution_count":29,"outputs":[]},{"cell_type":"code","source":"","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# for i in range(1):\nprompt = 'Given the context delimited by triple backticks ```'+ essay + '```, generate some questions from the given context. Questions:'\n#     input_ids = tokenizer.encode(prompt, return_tensors='pt')\n#     greedy_output = model.generate(input_ids, num_beams = 4,no_repeat_ngram_size=4,min_length=5,max_new_tokens=100)\n#     print(tokenizer.decode(greedy_output[0], skip_special_tokens=True))\n#     question = tokenizer.decode(greedy_output[0], skip_special_tokens=True)\n#     prompt2 = 'Given the context delimited by triple backticks ```{'+ essay + '}```,and the question delimited by single backticks `{'+ question + '}` generate an answer.Answer:'\n#     input_ids = tokenizer.encode(prompt2, return_tensors='pt')\n#     greedy_output = model.generate(input_ids, num_beams=4, no_repeat_ngram_size=2, max_new_tokens=100,do_sample=True)\n#     print(tokenizer.decode(greedy_output[0], skip_special_tokens=True))","metadata":{"execution":{"iopub.status.busy":"2023-11-03T05:13:02.289734Z","iopub.execute_input":"2023-11-03T05:13:02.290418Z","iopub.status.idle":"2023-11-03T05:13:02.307533Z","shell.execute_reply.started":"2023-11-03T05:13:02.290386Z","shell.execute_reply":"2023-11-03T05:13:02.306409Z"},"trusted":true},"execution_count":30,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# !zip -r bloomz.zip /kaggle/working/HindiQA-bloomz-560m","metadata":{"execution":{"iopub.status.busy":"2023-11-03T05:13:02.308743Z","iopub.execute_input":"2023-11-03T05:13:02.309108Z","iopub.status.idle":"2023-11-03T05:13:02.319192Z","shell.execute_reply.started":"2023-11-03T05:13:02.309074Z","shell.execute_reply":"2023-11-03T05:13:02.31819Z"},"trusted":true},"execution_count":31,"outputs":[]},{"cell_type":"code","source":"generator = transformers.pipeline('text2text-generation', model=model, tokenizer=tokenizer,do_sample=False)\nresult = generator(prompt, max_new_tokens=128)\nprint(result)","metadata":{"execution":{"iopub.status.busy":"2023-11-03T05:13:02.3206Z","iopub.execute_input":"2023-11-03T05:13:02.32099Z","iopub.status.idle":"2023-11-03T05:13:07.121229Z","shell.execute_reply.started":"2023-11-03T05:13:02.320958Z","shell.execute_reply":"2023-11-03T05:13:07.120114Z"},"trusted":true},"execution_count":32,"outputs":[{"name":"stdout","text":"[{'generated_text': 'अकबर के हिन्दू सामंत किस कारण मंदिर निर्माण तक नहीं करा सकते थे?'}]\n","output_type":"stream"}]},{"cell_type":"code","source":"question = result[0]['generated_text']","metadata":{"execution":{"iopub.status.busy":"2023-11-03T05:13:07.123673Z","iopub.execute_input":"2023-11-03T05:13:07.124499Z","iopub.status.idle":"2023-11-03T05:13:07.129876Z","shell.execute_reply.started":"2023-11-03T05:13:07.124461Z","shell.execute_reply":"2023-11-03T05:13:07.128843Z"},"trusted":true},"execution_count":33,"outputs":[]},{"cell_type":"code","source":"prompt2 = 'Given the context delimited by triple backticks ```'+ essay + '```,and the question delimited by single backticks `'+ question + '` generate an answer.Answer:'","metadata":{"execution":{"iopub.status.busy":"2023-11-03T05:13:07.130913Z","iopub.execute_input":"2023-11-03T05:13:07.131238Z","iopub.status.idle":"2023-11-03T05:13:07.142135Z","shell.execute_reply.started":"2023-11-03T05:13:07.131207Z","shell.execute_reply":"2023-11-03T05:13:07.141195Z"},"trusted":true},"execution_count":34,"outputs":[]},{"cell_type":"code","source":"generator = transformers.pipeline('text2text-generation', model=model, tokenizer=tokenizer,do_sample=False)\nresult = generator(prompt2, max_new_tokens=128)\nprint(result)","metadata":{"execution":{"iopub.status.busy":"2023-11-03T05:13:07.143266Z","iopub.execute_input":"2023-11-03T05:13:07.143958Z","iopub.status.idle":"2023-11-03T05:13:10.766342Z","shell.execute_reply.started":"2023-11-03T05:13:07.143926Z","shell.execute_reply":"2023-11-03T05:13:10.76505Z"},"trusted":true},"execution_count":35,"outputs":[{"name":"stdout","text":"[{'generated_text': 'उसकी अनुमति के बगैर'}]\n","output_type":"stream"}]}]}